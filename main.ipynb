{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from fastai import *\n",
    "from fastai.vision.all import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download MNIST dataset\n",
    "path = untar_data(URLs.MNIST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(predictions, targets):\n",
    "  sm = torch.log_softmax(predictions, dim=1)\n",
    "  return F.nll_loss(sm, targets.squeeze())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad(xb, yb, model):\n",
    "    preds = model(xb)\n",
    "    loss = mnist_loss(preds, yb)\n",
    "    loss.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model):\n",
    "    for xb, yb in train_dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(xb, yb):\n",
    "    pred_nums = torch.argmax(xb, axis=1)\n",
    "    return (pred_nums==yb.T).float().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb, yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs):\n",
    "    for i in range(epochs):\n",
    "        train_epoch(model)\n",
    "        print(validate_epoch(model), end=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicOptim:\n",
    "    def __init__(self,params,lr): self.params,self.lr = list(params),lr\n",
    "\n",
    "    def step(self, *args, **kwargs):\n",
    "        for p in self.params: p.data -= p.grad.data * self.lr\n",
    "\n",
    "    def zero_grad(self, *args, **kwargs):\n",
    "        for p in self.params: p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take images from downloaded MNIST sample\n",
    "train_digits = []\n",
    "valid_digits = []\n",
    "for i in range(0, 10):\n",
    "    train_digits.append((path/'training'/f'{i}').ls().sorted())\n",
    "    valid_digits.append((path/'testing'/f'{i}').ls().sorted())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images to tensor\n",
    "train_digits_tensors = []\n",
    "for digit in train_digits:\n",
    "    train_digits_tensors.append([tensor(Image.open(o)) for o in digit])\n",
    "\n",
    "valid_digits_tensors = []\n",
    "for digit in valid_digits:\n",
    "    valid_digits_tensors.append([tensor(Image.open(o)) for o in digit])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5949, 28, 28])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stacking tensors\n",
    "train_stacked_digits = []\n",
    "for digit in train_digits_tensors:\n",
    "    train_stacked_digits.append(torch.stack(digit).float()/255)\n",
    "    \n",
    "train_stacked_digits[9].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1009, 28, 28])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_stacked_digits = []\n",
    "for digit in valid_digits_tensors:\n",
    "    valid_stacked_digits.append(torch.stack(digit).float()/255)\n",
    "    \n",
    "valid_stacked_digits[9].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.cat(train_stacked_digits).view(-1, 28*28)\n",
    "\n",
    "train_y_arr = [[i]*len(train_digits[i]) for i in range(0, 10)]\n",
    "train_y_flatted = [item for sublist in train_y_arr for item in sublist]\n",
    "\n",
    "train_y = tensor(train_y_flatted).unsqueeze(1)\n",
    "\n",
    "# create train data set\n",
    "train_dset = list(zip(train_x, train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x = torch.cat(valid_stacked_digits).view(-1, 28*28)\n",
    "\n",
    "valid_y_arr = [[i]*len(valid_digits[i]) for i in range(0, 10)]\n",
    "valid_y_flatted = [item for sublist in valid_y_arr for item in sublist]\n",
    "\n",
    "valid_y = tensor(valid_y_flatted).unsqueeze(1)\n",
    "\n",
    "# create validation data set\n",
    "valid_dset = list(zip(valid_x, valid_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataLoader's\n",
    "train_dl = DataLoader(train_dset, batch_size=256)\n",
    "valid_dl = DataLoader(valid_dset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3296 0.4893 0.5827 0.6478 0.6869 0.7159 0.7369 0.7554 0.7695 0.7824 0.7921 0.7979 0.8043 0.8073 0.8123 0.8171 0.8211 0.8264 0.8293 0.8322 0.8349 0.8371 0.8395 0.8412 0.8433 0.8449 0.8467 0.8481 0.8492 0.8503 0.8518 0.8531 0.8537 0.8555 0.8571 0.8573 0.8583 0.8589 0.8599 0.8606 "
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "epoch = 40\n",
    "linear_model = nn.Linear(28*28, 10)\n",
    "opt = BasicOptim(linear_model.parameters(), lr)\n",
    "\n",
    "# train the model\n",
    "train_model(linear_model, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8606"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final accuracy ~ 0.86\n",
    "validate_epoch(linear_model)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4910ead06c0c7c2ef273303b97ce2d528212207f889db1c92efd055f57b1e10"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('3.9.13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
